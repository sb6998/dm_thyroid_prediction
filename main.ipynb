{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('Fin_Uci_thyroid1.csv')\n",
    "feat = data.iloc[:,0:-1]\n",
    "tar = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6928, 31)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      2176\n",
      "           1       1.00      0.34      0.51        68\n",
      "           2       0.29      0.09      0.14        43\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2287\n",
      "   macro avg       0.75      0.48      0.54      2287\n",
      "weighted avg       0.95      0.96      0.95      2287\n",
      "\n",
      "3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      2176\n",
      "           1       0.78      0.37      0.50        68\n",
      "           2       0.29      0.19      0.23        43\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      2287\n",
      "   macro avg       0.68      0.51      0.57      2287\n",
      "weighted avg       0.95      0.95      0.95      2287\n",
      "\n",
      "4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      2176\n",
      "           1       0.95      0.31      0.47        68\n",
      "           2       0.25      0.09      0.14        43\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2287\n",
      "   macro avg       0.72      0.47      0.53      2287\n",
      "weighted avg       0.95      0.96      0.95      2287\n",
      "\n",
      "5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      2176\n",
      "           1       0.96      0.32      0.48        68\n",
      "           2       0.33      0.19      0.24        43\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2287\n",
      "   macro avg       0.75      0.50      0.57      2287\n",
      "weighted avg       0.95      0.96      0.95      2287\n",
      "\n",
      "6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      2176\n",
      "           1       1.00      0.31      0.47        68\n",
      "           2       0.27      0.09      0.14        43\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2287\n",
      "   macro avg       0.74      0.47      0.53      2287\n",
      "weighted avg       0.95      0.96      0.95      2287\n",
      "\n",
      "7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      2176\n",
      "           1       0.95      0.31      0.47        68\n",
      "           2       0.26      0.12      0.16        43\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2287\n",
      "   macro avg       0.73      0.47      0.54      2287\n",
      "weighted avg       0.95      0.96      0.95      2287\n",
      "\n",
      "8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      2176\n",
      "           1       1.00      0.31      0.47        68\n",
      "           2       0.12      0.02      0.04        43\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2287\n",
      "   macro avg       0.70      0.44      0.50      2287\n",
      "weighted avg       0.95      0.96      0.95      2287\n",
      "\n",
      "9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      2176\n",
      "           1       1.00      0.31      0.47        68\n",
      "           2       0.25      0.07      0.11        43\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2287\n",
      "   macro avg       0.74      0.46      0.52      2287\n",
      "weighted avg       0.95      0.96      0.95      2287\n",
      "\n",
      "10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      2176\n",
      "           1       1.00      0.29      0.45        68\n",
      "           2       0.00      0.00      0.00        43\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2287\n",
      "   macro avg       0.65      0.43      0.48      2287\n",
      "weighted avg       0.94      0.96      0.94      2287\n",
      "\n",
      "11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      2176\n",
      "           1       0.95      0.29      0.45        68\n",
      "           2       0.25      0.07      0.11        43\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2287\n",
      "   macro avg       0.72      0.45      0.51      2287\n",
      "weighted avg       0.95      0.96      0.95      2287\n",
      "\n",
      "12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      2176\n",
      "           1       0.95      0.29      0.45        68\n",
      "           2       0.20      0.02      0.04        43\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2287\n",
      "   macro avg       0.70      0.44      0.49      2287\n",
      "weighted avg       0.95      0.96      0.95      2287\n",
      "\n",
      "13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      2176\n",
      "           1       0.95      0.29      0.45        68\n",
      "           2       0.20      0.02      0.04        43\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2287\n",
      "   macro avg       0.70      0.44      0.49      2287\n",
      "weighted avg       0.95      0.96      0.95      2287\n",
      "\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      2176\n",
      "           1       0.95      0.28      0.43        68\n",
      "           2       0.20      0.02      0.04        43\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2287\n",
      "   macro avg       0.70      0.43      0.48      2287\n",
      "weighted avg       0.95      0.96      0.94      2287\n",
      "\n",
      "15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      2176\n",
      "           1       0.95      0.29      0.45        68\n",
      "           2       0.33      0.05      0.08        43\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2287\n",
      "   macro avg       0.75      0.45      0.50      2287\n",
      "weighted avg       0.95      0.96      0.95      2287\n",
      "\n",
      "16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      2176\n",
      "           1       0.94      0.25      0.40        68\n",
      "           2       0.00      0.00      0.00        43\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2287\n",
      "   macro avg       0.63      0.42      0.46      2287\n",
      "weighted avg       0.94      0.96      0.94      2287\n",
      "\n",
      "17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      2176\n",
      "           1       0.95      0.26      0.41        68\n",
      "           2       0.00      0.00      0.00        43\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2287\n",
      "   macro avg       0.64      0.42      0.46      2287\n",
      "weighted avg       0.94      0.96      0.94      2287\n",
      "\n",
      "18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      2176\n",
      "           1       1.00      0.25      0.40        68\n",
      "           2       0.00      0.00      0.00        43\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2287\n",
      "   macro avg       0.65      0.42      0.46      2287\n",
      "weighted avg       0.94      0.96      0.94      2287\n",
      "\n",
      "19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      2176\n",
      "           1       0.94      0.25      0.40        68\n",
      "           2       0.00      0.00      0.00        43\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2287\n",
      "   macro avg       0.63      0.42      0.46      2287\n",
      "weighted avg       0.94      0.96      0.94      2287\n",
      "\n",
      "20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      2176\n",
      "           1       1.00      0.25      0.40        68\n",
      "           2       0.00      0.00      0.00        43\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2287\n",
      "   macro avg       0.65      0.42      0.46      2287\n",
      "weighted avg       0.94      0.96      0.94      2287\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      2176\n",
      "           1       1.00      0.25      0.40        68\n",
      "           2       0.00      0.00      0.00        43\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2287\n",
      "   macro avg       0.65      0.42      0.46      2287\n",
      "weighted avg       0.94      0.96      0.94      2287\n",
      "\n",
      "22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      2176\n",
      "           1       1.00      0.25      0.40        68\n",
      "           2       0.00      0.00      0.00        43\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2287\n",
      "   macro avg       0.65      0.42      0.46      2287\n",
      "weighted avg       0.94      0.96      0.94      2287\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      2176\n",
      "           1       1.00      0.25      0.40        68\n",
      "           2       0.00      0.00      0.00        43\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2287\n",
      "   macro avg       0.65      0.42      0.46      2287\n",
      "weighted avg       0.94      0.96      0.94      2287\n",
      "\n",
      "24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      2176\n",
      "           1       1.00      0.25      0.40        68\n",
      "           2       0.00      0.00      0.00        43\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2287\n",
      "   macro avg       0.65      0.42      0.46      2287\n",
      "weighted avg       0.94      0.96      0.94      2287\n",
      "\n",
      "25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      2176\n",
      "           1       1.00      0.25      0.40        68\n",
      "           2       0.00      0.00      0.00        43\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2287\n",
      "   macro avg       0.65      0.42      0.46      2287\n",
      "weighted avg       0.94      0.96      0.94      2287\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "x = StandardScaler().fit_transform(feat)\n",
    "pca = PCA(n_components=9)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = principalComponents)\n",
    "from knn import knn_\n",
    "knn_(principalDf,tar,0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\quant\\thyroid\\dm_thyroid_prediction\\nn.py:26: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  x_tr = scaler.transform(x_tr)\n",
      "D:\\quant\\thyroid\\dm_thyroid_prediction\\nn.py:27: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  x_te = scaler.transform(x_te)\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0926 15:28:24.768398 24748 deprecation.py:506] From D:\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4433 samples, validate on 1109 samples\n",
      "Epoch 1/50\n",
      "4433/4433 [==============================] - 1s 140us/sample - loss: 1.0021 - acc: 0.6073 - val_loss: 0.3825 - val_acc: 0.9432\n",
      "Epoch 2/50\n",
      "4433/4433 [==============================] - 0s 77us/sample - loss: 0.3924 - acc: 0.9362 - val_loss: 0.2765 - val_acc: 0.9432\n",
      "Epoch 3/50\n",
      "4433/4433 [==============================] - 0s 66us/sample - loss: 0.3074 - acc: 0.9468 - val_loss: 0.2470 - val_acc: 0.9432\n",
      "Epoch 4/50\n",
      "4433/4433 [==============================] - 0s 73us/sample - loss: 0.2638 - acc: 0.9488 - val_loss: 0.2258 - val_acc: 0.9432\n",
      "Epoch 5/50\n",
      "4433/4433 [==============================] - 0s 70us/sample - loss: 0.2395 - acc: 0.9513 - val_loss: 0.2051 - val_acc: 0.9441\n",
      "Epoch 6/50\n",
      "4433/4433 [==============================] - 0s 72us/sample - loss: 0.2308 - acc: 0.9520 - val_loss: 0.1925 - val_acc: 0.9450\n",
      "Epoch 7/50\n",
      "4433/4433 [==============================] - 0s 74us/sample - loss: 0.2108 - acc: 0.9540 - val_loss: 0.1793 - val_acc: 0.9468\n",
      "Epoch 8/50\n",
      "4433/4433 [==============================] - 0s 74us/sample - loss: 0.2004 - acc: 0.9553 - val_loss: 0.1702 - val_acc: 0.9513\n",
      "Epoch 9/50\n",
      "4433/4433 [==============================] - 0s 72us/sample - loss: 0.1968 - acc: 0.9571 - val_loss: 0.1641 - val_acc: 0.9531\n",
      "Epoch 10/50\n",
      "4433/4433 [==============================] - 0s 74us/sample - loss: 0.1859 - acc: 0.9587 - val_loss: 0.1528 - val_acc: 0.9540\n",
      "Epoch 11/50\n",
      "4433/4433 [==============================] - 0s 72us/sample - loss: 0.1797 - acc: 0.9585 - val_loss: 0.1486 - val_acc: 0.9540\n",
      "Epoch 12/50\n",
      "4433/4433 [==============================] - 0s 72us/sample - loss: 0.1600 - acc: 0.9587 - val_loss: 0.1419 - val_acc: 0.9549\n",
      "Epoch 13/50\n",
      "4433/4433 [==============================] - 0s 72us/sample - loss: 0.1575 - acc: 0.9605 - val_loss: 0.1358 - val_acc: 0.9549\n",
      "Epoch 14/50\n",
      "4433/4433 [==============================] - 0s 71us/sample - loss: 0.1413 - acc: 0.9617 - val_loss: 0.1305 - val_acc: 0.9576\n",
      "Epoch 15/50\n",
      "4433/4433 [==============================] - 0s 68us/sample - loss: 0.1395 - acc: 0.9630 - val_loss: 0.1285 - val_acc: 0.9576\n",
      "Epoch 16/50\n",
      "4433/4433 [==============================] - 0s 76us/sample - loss: 0.1336 - acc: 0.9635 - val_loss: 0.1220 - val_acc: 0.9603\n",
      "Epoch 17/50\n",
      "4433/4433 [==============================] - 0s 72us/sample - loss: 0.1240 - acc: 0.9626 - val_loss: 0.1169 - val_acc: 0.9621\n",
      "Epoch 18/50\n",
      "4433/4433 [==============================] - 0s 64us/sample - loss: 0.1132 - acc: 0.9666 - val_loss: 0.1132 - val_acc: 0.9630\n",
      "Epoch 19/50\n",
      "4433/4433 [==============================] - 0s 70us/sample - loss: 0.1205 - acc: 0.9659 - val_loss: 0.1151 - val_acc: 0.9630\n",
      "Epoch 20/50\n",
      "4433/4433 [==============================] - 0s 74us/sample - loss: 0.1117 - acc: 0.9657 - val_loss: 0.1121 - val_acc: 0.9639\n",
      "Epoch 21/50\n",
      "4433/4433 [==============================] - 0s 63us/sample - loss: 0.1150 - acc: 0.9664 - val_loss: 0.1071 - val_acc: 0.9630\n",
      "Epoch 22/50\n",
      "4433/4433 [==============================] - 0s 65us/sample - loss: 0.1039 - acc: 0.9673 - val_loss: 0.1087 - val_acc: 0.9639\n",
      "Epoch 23/50\n",
      "4433/4433 [==============================] - 0s 67us/sample - loss: 0.1012 - acc: 0.9677 - val_loss: 0.1047 - val_acc: 0.9657\n",
      "Epoch 24/50\n",
      "4433/4433 [==============================] - 0s 66us/sample - loss: 0.1002 - acc: 0.9693 - val_loss: 0.1022 - val_acc: 0.9666\n",
      "Epoch 25/50\n",
      "4433/4433 [==============================] - 0s 66us/sample - loss: 0.0907 - acc: 0.9691 - val_loss: 0.1053 - val_acc: 0.9666\n",
      "Epoch 26/50\n",
      "4433/4433 [==============================] - 0s 76us/sample - loss: 0.0879 - acc: 0.9729 - val_loss: 0.0979 - val_acc: 0.9675\n",
      "Epoch 27/50\n",
      "4433/4433 [==============================] - 0s 72us/sample - loss: 0.0896 - acc: 0.9704 - val_loss: 0.1010 - val_acc: 0.9675\n",
      "Epoch 28/50\n",
      "4433/4433 [==============================] - 0s 68us/sample - loss: 0.0859 - acc: 0.9716 - val_loss: 0.0980 - val_acc: 0.9675\n",
      "Epoch 29/50\n",
      "4433/4433 [==============================] - 0s 73us/sample - loss: 0.0829 - acc: 0.9727 - val_loss: 0.0958 - val_acc: 0.9684\n",
      "Epoch 30/50\n",
      "4433/4433 [==============================] - 0s 73us/sample - loss: 0.0753 - acc: 0.9732 - val_loss: 0.0978 - val_acc: 0.9684\n",
      "Epoch 31/50\n",
      "4433/4433 [==============================] - 0s 74us/sample - loss: 0.0786 - acc: 0.9711 - val_loss: 0.0939 - val_acc: 0.9702\n",
      "Epoch 32/50\n",
      "4433/4433 [==============================] - 0s 74us/sample - loss: 0.0741 - acc: 0.9745 - val_loss: 0.1009 - val_acc: 0.9675\n",
      "Epoch 33/50\n",
      "4433/4433 [==============================] - 0s 73us/sample - loss: 0.0719 - acc: 0.9763 - val_loss: 0.0926 - val_acc: 0.9702\n",
      "Epoch 34/50\n",
      "4433/4433 [==============================] - 0s 70us/sample - loss: 0.0690 - acc: 0.9736 - val_loss: 0.0964 - val_acc: 0.9684\n",
      "Epoch 35/50\n",
      "4433/4433 [==============================] - 0s 72us/sample - loss: 0.0724 - acc: 0.9750 - val_loss: 0.0944 - val_acc: 0.9693\n",
      "Epoch 36/50\n",
      "4433/4433 [==============================] - 0s 72us/sample - loss: 0.0716 - acc: 0.9750 - val_loss: 0.0978 - val_acc: 0.9693\n",
      "1386/1386 [==============================] - 0s 45us/sample - loss: 0.0827 - acc: 0.9733\n",
      "Accuracy 0.97330445\n"
     ]
    }
   ],
   "source": [
    "from nn import nn\n",
    "history=nn(feat,tar,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1316\n",
      "           1       1.00      0.02      0.05        41\n",
      "           2       0.29      0.07      0.11        29\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      1386\n",
      "   macro avg       0.75      0.36      0.38      1386\n",
      "weighted avg       0.94      0.95      0.93      1386\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from naivebayes import naive_bayes\n",
    "naive_bayes(feat,tar,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1316\n",
      "           1       1.00      1.00      1.00        41\n",
      "           2       0.46      0.45      0.46        29\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1386\n",
      "   macro avg       0.82      0.81      0.81      1386\n",
      "weighted avg       0.98      0.98      0.98      1386\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost_ import xgboost_\n",
    "xgboost_(feat,tar,0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
